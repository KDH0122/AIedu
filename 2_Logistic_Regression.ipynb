{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic_Regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Logistic Regression"],"metadata":{"id":"uAbOiRaMvJo8"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"KVqRqamlvEKl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659585941057,"user_tz":-540,"elapsed":37272,"user":{"displayName":"김민정","userId":"17052167108138666711"}},"outputId":"17e55cff-ae0c-425c-9d76-fe562b55ae7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Run_count : [1000], Train_cost =[0.7159], W =[-0.1279 0.0908], b =[0.5313],                \n","pred =[0.6337 0.5726 0.5502 0.6747 0.5091 0.5635],                \n","pred_Y = [1 1 1 1 1 1 ],                \n","true_Y=  [0 0 0 1 1 1 ],                \n","accuracy = [50.00%] \n","\n","Run_count : [2000], Train_cost =[0.6470], W =[-0.0607 0.2504], b =[-0.2800],                \n","pred =[0.5866 0.5568 0.4945 0.7007 0.5267 0.6030],                \n","pred_Y = [1 1 0 1 1 1 ],                \n","true_Y=  [0 0 0 1 1 1 ],                \n","accuracy = [66.67%] \n","\n","Run_count : [3000], Train_cost =[0.5883], W =[0.0111 0.3866], b =[-1.0303],                \n","pred =[0.5379 0.5434 0.4470 0.7160 0.5489 0.6392],                \n","pred_Y = [1 1 0 1 1 1 ],                \n","true_Y=  [0 0 0 1 1 1 ],                \n","accuracy = [66.67%] \n","\n","Run_count : [4000], Train_cost =[0.5382], W =[0.0772 0.5131], b =[-1.7231],                \n","pred =[0.4927 0.5312 0.4042 0.7305 0.5694 0.6716],                \n","pred_Y = [0 1 0 1 1 1 ],                \n","true_Y=  [0 0 0 1 1 1 ],                \n","accuracy = [83.33%] \n","\n","Run_count : [5000], Train_cost =[0.4954], W =[0.1379 0.6309], b =[-2.3637],                \n","pred =[0.4514 0.5201 0.3658 0.7440 0.5881 0.7004],                \n","pred_Y = [0 1 0 1 1 1 ],                \n","true_Y=  [0 0 0 1 1 1 ],                \n","accuracy = [83.33%] \n","\n","Run_count : [6000], Train_cost =[0.4586], W =[0.1938 0.7406], b =[-2.9573],                \n","pred =[0.4139 0.5099 0.3316 0.7565 0.6052 0.7259],                \n","pred_Y = [0 1 0 1 1 1 ],                \n","true_Y=  [0 0 0 1 1 1 ],                \n","accuracy = [83.33%] \n","\n","Run_count : [7000], Train_cost =[0.4269], W =[0.2454 0.8430], b =[-3.5088],                \n","pred =[0.3802 0.5005 0.3013 0.7680 0.6207 0.7484],                \n","pred_Y = [0 1 0 1 1 1 ],                \n","true_Y=  [0 0 0 1 1 1 ],                \n","accuracy = [83.33%] \n","\n","Run_count : [8000], Train_cost =[0.3994], W =[0.2933 0.9387], b =[-4.0226],                \n","pred =[0.3498 0.4917 0.2745 0.7786 0.6349 0.7683],                \n","pred_Y = [0 0 0 1 1 1 ],                \n","true_Y=  [0 0 0 1 1 1 ],                \n","accuracy = [100.00%] \n","\n","Run_count : [9000], Train_cost =[0.3753], W =[0.3378 1.0284], b =[-4.5027],                \n","pred =[0.3226 0.4834 0.2507 0.7884 0.6478 0.7858],                \n","pred_Y = [0 0 0 1 1 1 ],                \n","true_Y=  [0 0 0 1 1 1 ],                \n","accuracy = [100.00%] \n","\n","Run_count : [10000], Train_cost =[0.3542], W =[0.3793 1.1127], b =[-4.9527],                \n","pred =[0.2982 0.4757 0.2297 0.7973 0.6595 0.8013],                \n","pred_Y = [0 0 0 1 1 1 ],                \n","true_Y=  [0 0 0 1 1 1 ],                \n","accuracy = [100.00%] \n","Optimization Finished!\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","\n","learning_rate = 0.01\n","training_cnt = 10000\n","display_step = 1000\n","\n","X = np.array([[2, 3], [4, 3], [4, 2], [2, 5], [6, 3], [5, 4] ], dtype= np.float32)\n","Y = np.array([[0], [0], [0], [1], [1], [1]])\n","\n","W = tf.Variable(tf.random.normal([2, 1]), name='weight') \n","b = tf.Variable(tf.random.normal([1]), name='bias')  \n","\n","for epoch in range(training_cnt):\n","    with tf.GradientTape() as tape:\n","      pred = tf.sigmoid(tf.matmul(X ,W) + b)\n","      cost = -tf.reduce_mean(Y * tf.math.log(pred) + (1 - Y) * tf.math.log(1 - pred) )\n","      predicted = tf.cast(pred > 0.5, dtype=tf.float32)\n","      accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n","    if (epoch+1) % display_step == 0:\n","      print(\"\\nRun_count : [%04d], Train_cost =[%.4f], W =[%.4f %.4f], b =[%.4f], \\\n","               \\npred =[%.4f %.4f %.4f %.4f %.4f %.4f], \\\n","               \\npred_Y = [%d %d %d %d %d %d ], \\\n","               \\ntrue_Y=  [%d %d %d %d %d %d ], \\\n","               \\naccuracy = [%.2f%%] \" \n","              % (epoch+1, cost, W[0], W[1], b, \n","                 pred[0], pred[1], pred[2], pred[3], pred[4], pred[5],\n","                 predicted[0], predicted[1], predicted[2], predicted[3], predicted[4], predicted[5],\n","                 Y[0], Y[1], Y[2], Y[3], Y[4],Y[5],\n","                 accuracy*100))\n","    W_grad, b_grad = tape.gradient(cost, [W, b])\n","    W.assign_sub(learning_rate * W_grad)\n","    b.assign_sub(learning_rate * b_grad)\n","\n","print(\"Optimization Finished!\") "]},{"cell_type":"markdown","source":["### 1) 파라메터 값 설정\n","- 머신러닝을 위한 기초 파라메터\n","- learning_rate :  값이 너무 적으면 Train 되지 않을 수 있고     \n","  값이 너무 크면 overshooting이 발생할 수 있다.\n","- training_cnt : data set에 대한 training 반복 횟수\n"],"metadata":{"id":"qLHExnPHZprc"}},{"cell_type":"code","source":["# 파라메터값 설정\n","learning_rate = 0.01\n","training_cnt = 10000\n","display_step = 100  # 원하는 출력 위치 조정"],"metadata":{"id":"QXO2KfCKTkP2","executionInfo":{"status":"ok","timestamp":1659586235033,"user_tz":-540,"elapsed":311,"user":{"displayName":"김민정","userId":"17052167108138666711"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### 2) 트레이닝 데이터 변수 선언\n","- 입력으로 들어가는 x data(input 2개), y data(output 1개) 설정\n","- numpy array를 사용 "],"metadata":{"id":"IvMe6HVWZzmj"}},{"cell_type":"code","source":["X = np.array([[2, 3], [4, 3], [4, 2], [2, 5], [6, 3], [5, 4] ], dtype=np.float32)\n","Y = np.array([[0], [0], [0], [1], [1], [1]])"],"metadata":{"id":"io_77wiuZxpK","executionInfo":{"status":"ok","timestamp":1659586240955,"user_tz":-540,"elapsed":299,"user":{"displayName":"김민정","userId":"17052167108138666711"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### 3) tf.random.normal\n","- bias, weight 초기값을 난수로 생성"],"metadata":{"id":"zo93ILa3anQ4"}},{"cell_type":"code","source":["W = tf.Variable(tf.random.normal([2, 1]), name='weight')\n","b = tf.Variable(tf.random.normal([1]), name='bias')"],"metadata":{"id":"Jw87Eo4TabWK","executionInfo":{"status":"ok","timestamp":1659586243233,"user_tz":-540,"elapsed":438,"user":{"displayName":"김민정","userId":"17052167108138666711"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### 4) sigmoid 함수 사용\n","- 기존 pred 계산에 sigmoid 함수를 적용해 0~1사이의 값으로 변환\n","- sigmoid function => H(X) = 1/(1+𝑒^−z )\n","- z = XW + b\n"],"metadata":{"id":"Sf8_I_Jrax0y"}},{"cell_type":"code","source":["pred = tf.sigmoid(tf.matmul(X ,W) + b)"],"metadata":{"id":"kavLzKsdauQC","executionInfo":{"status":"ok","timestamp":1659586252533,"user_tz":-540,"elapsed":286,"user":{"displayName":"김민정","userId":"17052167108138666711"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### 5) cost function\n","- 0~1사이의 값을 근사화 하기 위해서 log함수를 사용\n","- 𝐶(𝐻(𝑥),𝑦)=1/𝑚 ∑(𝑦𝑙𝑜𝑔(𝐻(𝑥)) −(1 −𝑦)log⁡(1 −𝐻(𝑥)) "],"metadata":{"id":"4cqAt0f1bDk3"}},{"cell_type":"code","source":["cost = -tf.reduce_mean(Y * tf.math.log(pred) + (1 - Y) * tf.math.log(1 - pred) )"],"metadata":{"id":"7B0IHiJYa4RR","executionInfo":{"status":"ok","timestamp":1659586259770,"user_tz":-540,"elapsed":282,"user":{"displayName":"김민정","userId":"17052167108138666711"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### 6) 학습\n","- gradient decent 함수 사용(경사 하강법) \n","-  파라미터 $W$, $b$ 에 대해 손실을 미분하는 과정으로, 파라미터를 증가시킬 때 손실이 얼마나 변화하는지를 알아본다. \n","- with tf.GradientTape() as tape: 안에서 계산을 하면 tape에 계산 과정을 기록해두었다가 tape.gradient를 이용해서 미분을 자동으로 구할 수 있다\n"],"metadata":{"id":"1Jeug3skbOTM"}},{"cell_type":"code","source":["with tf.GradientTape() as tape:\n","  pred = tf.sigmoid(tf.matmul(X ,W) + b)\n","  cost = -tf.reduce_mean(Y * tf.math.log(pred) + (1 - Y) * tf.math.log(1 - pred))\n","W_grad, b_grad = tape.gradient(cost, [W, b])"],"metadata":{"id":"4uruOlj3bL9z","executionInfo":{"status":"ok","timestamp":1659586483536,"user_tz":-540,"elapsed":303,"user":{"displayName":"김민정","userId":"17052167108138666711"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["- $w←w−η∂w$ 의 식으로 파라미터를 수정\n","- $η$ 는 학습률\n","- 경사(미분)을 따라 손실을 줄여나가기 때문에 경사하강법이라고 부름\n","- a.assign_sub(b)는 a = a - b 와 같다"],"metadata":{"id":"_V69-ZCkD8Ec"}},{"cell_type":"code","source":["W.assign_sub(learning_rate * W_grad)\n","b.assign_sub(learning_rate * b_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IypCh5AZDN_y","executionInfo":{"status":"ok","timestamp":1659586485220,"user_tz":-540,"elapsed":274,"user":{"displayName":"김민정","userId":"17052167108138666711"}},"outputId":"dac736e5-3651-4a0f-d681-87452d6f30a9"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.15444584], dtype=float32)>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["### 7) 학습된 예측값을 0과 1로 변환\n","- 0~1사이로 학습된 예측값을 0과 1로 나누어 분류할 수 있도록 만듬"],"metadata":{"id":"VlstNveGbrZZ"}},{"cell_type":"code","source":["predicted = tf.cast(pred > 0.5, dtype=tf.float32)"],"metadata":{"id":"25OVLZ0ZbL27","executionInfo":{"status":"ok","timestamp":1659586495715,"user_tz":-540,"elapsed":319,"user":{"displayName":"김민정","userId":"17052167108138666711"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### 9) 정확도\n","- accuracy를 계산하여 분류가 정확한지 확인\n","- 예측값과 실제 데이터의 일치 여부 계산 \n","- 아래 코드는 평균을 이용한 정확도 계산"],"metadata":{"id":"GKfTbdKTb-y5"}},{"cell_type":"code","source":["accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"],"metadata":{"id":"yxYEX4L-b7Nu","executionInfo":{"status":"ok","timestamp":1659586498816,"user_tz":-540,"elapsed":268,"user":{"displayName":"김민정","userId":"17052167108138666711"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## (2) 모델 실행(run/update)\n","- pred는 sigmoid 함수를 통해 0~1사이의 값으로 나온다\n","- predicted는 pred에서 나온 값을 0과 1로 변환 시킨 값이다\n","- accuracy는 예측한 Y값이 실제 Y값과 얼마나 일치하는가"],"metadata":{"id":"kI2kraHmcdZh"}},{"cell_type":"code","source":["for epoch in range(training_cnt):\n","    with tf.GradientTape() as tape:\n","      pred = tf.sigmoid(tf.matmul(X ,W) + b)\n","      cost = -tf.reduce_mean(Y * tf.math.log(pred) + (1 - Y) * tf.math.log(1 - pred) )\n","      predicted = tf.cast(pred > 0.5, dtype=tf.float32)\n","      accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n","    if (epoch+1) % display_step == 0:\n","      print(\"\\nRun_count : [%04d], Train_cost =[%.4f], W =[%.4f %.4f], b =[%.4f], \\\n","              \\npred =[%.4f %.4f %.4f %.4f %.4f %.4f], \\\n","              \\npred_Y = [%d %d %d %d %d %d ], \\\n","              \\ntrue_Y=  [%d %d %d %d %d %d ], \\\n","              \\naccuracy = [%.2f%%] \" \n","              % (epoch+1, cost, W[0], W[1], b, \n","                 pred[0], pred[1], pred[2], pred[3], pred[4], pred[5],\n","                 predicted[0], predicted[1], predicted[2], predicted[3], predicted[4], predicted[5],\n","                 Y[0], Y[1], Y[2], Y[3], Y[4],Y[5],\n","                 accuracy*100))\n","    W_grad, b_grad = tape.gradient(cost, [W, b])\n","    W.assign_sub(learning_rate * W_grad)\n","    b.assign_sub(learning_rate * b_grad)\n","\n","print(\"Optimization Finished!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9twcTM7cigH","executionInfo":{"status":"ok","timestamp":1659586576269,"user_tz":-540,"elapsed":30997,"user":{"displayName":"김민정","userId":"17052167108138666711"}},"outputId":"c3d1b3e0-3084-4a78-be64-9e545cd97a37"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Run_count : [0100], Train_cost =[0.7015], W =[-0.3124 0.4486], b =[0.1309],               \n","pred =[0.7010 0.5566 0.4449 0.8519 0.4019 0.5899],               \n","pred_Y = [1 1 0 1 0 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [50.00%] \n","\n","Run_count : [0200], Train_cost =[0.6830], W =[-0.2381 0.3794], b =[0.0411],               \n","pred =[0.6689 0.5565 0.4620 0.8118 0.4380 0.5910],               \n","pred_Y = [1 1 0 1 0 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [50.00%] \n","\n","Run_count : [0300], Train_cost =[0.6704], W =[-0.1830 0.3343], b =[-0.0453],               \n","pred =[0.6437 0.5562 0.4729 0.7791 0.4650 0.5931],               \n","pred_Y = [1 1 0 1 0 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [50.00%] \n","\n","Run_count : [0400], Train_cost =[0.6610], W =[-0.1423 0.3077], b =[-0.1291],               \n","pred =[0.6247 0.5559 0.4793 0.7549 0.4850 0.5963],               \n","pred_Y = [1 1 0 1 0 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [50.00%] \n","\n","Run_count : [0500], Train_cost =[0.6532], W =[-0.1122 0.2943], b =[-0.2109],               \n","pred =[0.6100 0.5555 0.4822 0.7381 0.4996 0.5999],               \n","pred_Y = [1 1 0 1 0 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [50.00%] \n","\n","Run_count : [0600], Train_cost =[0.6462], W =[-0.0895 0.2898], b =[-0.2911],               \n","pred =[0.5985 0.5549 0.4826 0.7269 0.5103 0.6036],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [0700], Train_cost =[0.6397], W =[-0.0719 0.2915], b =[-0.3700],               \n","pred =[0.5892 0.5540 0.4814 0.7198 0.5183 0.6074],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [0800], Train_cost =[0.6334], W =[-0.0578 0.2972], b =[-0.4478],               \n","pred =[0.5813 0.5530 0.4789 0.7156 0.5243 0.6112],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [0900], Train_cost =[0.6273], W =[-0.0460 0.3056], b =[-0.5248],               \n","pred =[0.5745 0.5519 0.4757 0.7133 0.5291 0.6149],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [1000], Train_cost =[0.6213], W =[-0.0357 0.3158], b =[-0.6010],               \n","pred =[0.5683 0.5507 0.4720 0.7123 0.5330 0.6186],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [1100], Train_cost =[0.6154], W =[-0.0265 0.3270], b =[-0.6764],               \n","pred =[0.5626 0.5495 0.4679 0.7121 0.5363 0.6222],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [1200], Train_cost =[0.6096], W =[-0.0181 0.3390], b =[-0.7511],               \n","pred =[0.5571 0.5482 0.4637 0.7125 0.5392 0.6258],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [1300], Train_cost =[0.6039], W =[-0.0102 0.3514], b =[-0.8252],               \n","pred =[0.5520 0.5469 0.4593 0.7133 0.5419 0.6294],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [1400], Train_cost =[0.5982], W =[-0.0026 0.3640], b =[-0.8987],               \n","pred =[0.5469 0.5457 0.4549 0.7143 0.5444 0.6329],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [1500], Train_cost =[0.5927], W =[0.0048 0.3768], b =[-0.9716],               \n","pred =[0.5420 0.5444 0.4505 0.7155 0.5468 0.6364],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [1600], Train_cost =[0.5873], W =[0.0119 0.3897], b =[-1.0439],               \n","pred =[0.5372 0.5431 0.4460 0.7167 0.5490 0.6398],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [1700], Train_cost =[0.5819], W =[0.0190 0.4025], b =[-1.1156],               \n","pred =[0.5324 0.5419 0.4416 0.7181 0.5512 0.6432],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [1800], Train_cost =[0.5766], W =[0.0259 0.4153], b =[-1.1867],               \n","pred =[0.5277 0.5406 0.4372 0.7195 0.5534 0.6466],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [1900], Train_cost =[0.5715], W =[0.0327 0.4281], b =[-1.2572],               \n","pred =[0.5231 0.5394 0.4328 0.7209 0.5555 0.6499],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [2000], Train_cost =[0.5664], W =[0.0394 0.4408], b =[-1.3272],               \n","pred =[0.5185 0.5381 0.4285 0.7223 0.5576 0.6532],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [2100], Train_cost =[0.5613], W =[0.0460 0.4535], b =[-1.3966],               \n","pred =[0.5140 0.5369 0.4242 0.7237 0.5597 0.6564],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [2200], Train_cost =[0.5564], W =[0.0526 0.4660], b =[-1.4655],               \n","pred =[0.5095 0.5357 0.4200 0.7251 0.5618 0.6597],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [2300], Train_cost =[0.5515], W =[0.0591 0.4785], b =[-1.5339],               \n","pred =[0.5050 0.5345 0.4158 0.7265 0.5638 0.6628],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [2400], Train_cost =[0.5467], W =[0.0656 0.4909], b =[-1.6017],               \n","pred =[0.5006 0.5333 0.4116 0.7279 0.5658 0.6660],               \n","pred_Y = [1 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [66.67%] \n","\n","Run_count : [2500], Train_cost =[0.5420], W =[0.0720 0.5032], b =[-1.6689],               \n","pred =[0.4962 0.5322 0.4075 0.7293 0.5678 0.6691],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [2600], Train_cost =[0.5374], W =[0.0784 0.5155], b =[-1.7357],               \n","pred =[0.4919 0.5310 0.4034 0.7307 0.5698 0.6722],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [2700], Train_cost =[0.5328], W =[0.0847 0.5276], b =[-1.8019],               \n","pred =[0.4876 0.5298 0.3994 0.7321 0.5717 0.6752],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [2800], Train_cost =[0.5283], W =[0.0909 0.5397], b =[-1.8676],               \n","pred =[0.4833 0.5287 0.3954 0.7335 0.5736 0.6782],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [2900], Train_cost =[0.5239], W =[0.0971 0.5516], b =[-1.9328],               \n","pred =[0.4791 0.5276 0.3914 0.7349 0.5756 0.6812],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [3000], Train_cost =[0.5195], W =[0.1032 0.5635], b =[-1.9975],               \n","pred =[0.4749 0.5264 0.3875 0.7362 0.5775 0.6841],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [3100], Train_cost =[0.5152], W =[0.1093 0.5753], b =[-2.0617],               \n","pred =[0.4707 0.5253 0.3837 0.7376 0.5793 0.6870],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [3200], Train_cost =[0.5110], W =[0.1153 0.5870], b =[-2.1254],               \n","pred =[0.4666 0.5242 0.3799 0.7389 0.5812 0.6898],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [3300], Train_cost =[0.5068], W =[0.1213 0.5987], b =[-2.1886],               \n","pred =[0.4626 0.5231 0.3761 0.7403 0.5830 0.6927],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [3400], Train_cost =[0.5027], W =[0.1272 0.6102], b =[-2.2514],               \n","pred =[0.4585 0.5221 0.3724 0.7416 0.5849 0.6955],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [3500], Train_cost =[0.4986], W =[0.1331 0.6217], b =[-2.3136],               \n","pred =[0.4546 0.5210 0.3687 0.7429 0.5867 0.6982],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [3600], Train_cost =[0.4947], W =[0.1390 0.6331], b =[-2.3754],               \n","pred =[0.4506 0.5199 0.3651 0.7442 0.5885 0.7009],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [3700], Train_cost =[0.4907], W =[0.1448 0.6444], b =[-2.4367],               \n","pred =[0.4467 0.5189 0.3615 0.7455 0.5902 0.7036],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [3800], Train_cost =[0.4869], W =[0.1505 0.6556], b =[-2.4975],               \n","pred =[0.4428 0.5178 0.3579 0.7468 0.5920 0.7063],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [3900], Train_cost =[0.4831], W =[0.1562 0.6668], b =[-2.5579],               \n","pred =[0.4390 0.5168 0.3544 0.7481 0.5938 0.7089],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [4000], Train_cost =[0.4793], W =[0.1618 0.6778], b =[-2.6178],               \n","pred =[0.4352 0.5157 0.3510 0.7493 0.5955 0.7115],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [4100], Train_cost =[0.4757], W =[0.1674 0.6888], b =[-2.6773],               \n","pred =[0.4314 0.5147 0.3475 0.7506 0.5972 0.7141],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [4200], Train_cost =[0.4720], W =[0.1730 0.6997], b =[-2.7364],               \n","pred =[0.4277 0.5137 0.3441 0.7518 0.5989 0.7166],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [4300], Train_cost =[0.4684], W =[0.1785 0.7106], b =[-2.7949],               \n","pred =[0.4240 0.5127 0.3408 0.7531 0.6006 0.7191],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [4400], Train_cost =[0.4649], W =[0.1840 0.7213], b =[-2.8531],               \n","pred =[0.4204 0.5117 0.3375 0.7543 0.6022 0.7216],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [4500], Train_cost =[0.4614], W =[0.1894 0.7320], b =[-2.9108],               \n","pred =[0.4168 0.5107 0.3342 0.7555 0.6039 0.7240],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [4600], Train_cost =[0.4580], W =[0.1948 0.7427], b =[-2.9682],               \n","pred =[0.4132 0.5097 0.3310 0.7567 0.6055 0.7264],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [4700], Train_cost =[0.4546], W =[0.2001 0.7532], b =[-3.0250],               \n","pred =[0.4097 0.5088 0.3278 0.7579 0.6071 0.7288],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [4800], Train_cost =[0.4513], W =[0.2054 0.7637], b =[-3.0815],               \n","pred =[0.4062 0.5078 0.3246 0.7591 0.6087 0.7311],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [4900], Train_cost =[0.4480], W =[0.2107 0.7741], b =[-3.1376],               \n","pred =[0.4028 0.5068 0.3215 0.7603 0.6103 0.7334],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [5000], Train_cost =[0.4448], W =[0.2159 0.7844], b =[-3.1932],               \n","pred =[0.3993 0.5059 0.3185 0.7614 0.6119 0.7357],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [5100], Train_cost =[0.4416], W =[0.2211 0.7947], b =[-3.2485],               \n","pred =[0.3959 0.5049 0.3154 0.7626 0.6135 0.7380],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [5200], Train_cost =[0.4385], W =[0.2262 0.8048], b =[-3.3033],               \n","pred =[0.3926 0.5040 0.3124 0.7637 0.6150 0.7402],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [5300], Train_cost =[0.4354], W =[0.2313 0.8150], b =[-3.3578],               \n","pred =[0.3893 0.5031 0.3094 0.7649 0.6165 0.7424],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [5400], Train_cost =[0.4323], W =[0.2364 0.8250], b =[-3.4119],               \n","pred =[0.3860 0.5021 0.3065 0.7660 0.6180 0.7446],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [5500], Train_cost =[0.4293], W =[0.2414 0.8350], b =[-3.4656],               \n","pred =[0.3828 0.5012 0.3036 0.7671 0.6195 0.7467],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [5600], Train_cost =[0.4263], W =[0.2463 0.8449], b =[-3.5189],               \n","pred =[0.3795 0.5003 0.3008 0.7682 0.6210 0.7488],               \n","pred_Y = [0 1 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [83.33%] \n","\n","Run_count : [5700], Train_cost =[0.4234], W =[0.2513 0.8548], b =[-3.5718],               \n","pred =[0.3764 0.4994 0.2979 0.7693 0.6225 0.7509],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [5800], Train_cost =[0.4205], W =[0.2562 0.8645], b =[-3.6244],               \n","pred =[0.3732 0.4985 0.2951 0.7704 0.6240 0.7530],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [5900], Train_cost =[0.4177], W =[0.2611 0.8743], b =[-3.6766],               \n","pred =[0.3701 0.4976 0.2924 0.7715 0.6254 0.7551],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [6000], Train_cost =[0.4149], W =[0.2659 0.8839], b =[-3.7284],               \n","pred =[0.3670 0.4967 0.2897 0.7726 0.6268 0.7571],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [6100], Train_cost =[0.4121], W =[0.2707 0.8935], b =[-3.7799],               \n","pred =[0.3640 0.4958 0.2870 0.7736 0.6283 0.7591],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [6200], Train_cost =[0.4094], W =[0.2754 0.9030], b =[-3.8310],               \n","pred =[0.3610 0.4950 0.2843 0.7747 0.6297 0.7610],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [6300], Train_cost =[0.4067], W =[0.2802 0.9125], b =[-3.8818],               \n","pred =[0.3580 0.4941 0.2817 0.7757 0.6310 0.7630],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [6400], Train_cost =[0.4041], W =[0.2849 0.9219], b =[-3.9322],               \n","pred =[0.3551 0.4932 0.2791 0.7768 0.6324 0.7649],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [6500], Train_cost =[0.4014], W =[0.2895 0.9312], b =[-3.9823],               \n","pred =[0.3522 0.4924 0.2765 0.7778 0.6338 0.7668],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [6600], Train_cost =[0.3989], W =[0.2941 0.9405], b =[-4.0320],               \n","pred =[0.3493 0.4915 0.2740 0.7788 0.6351 0.7687],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [6700], Train_cost =[0.3963], W =[0.2987 0.9497], b =[-4.0814],               \n","pred =[0.3464 0.4907 0.2715 0.7798 0.6365 0.7705],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [6800], Train_cost =[0.3938], W =[0.3033 0.9589], b =[-4.1305],               \n","pred =[0.3436 0.4898 0.2690 0.7808 0.6378 0.7723],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [6900], Train_cost =[0.3913], W =[0.3078 0.9680], b =[-4.1792],               \n","pred =[0.3408 0.4890 0.2666 0.7818 0.6391 0.7741],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [7000], Train_cost =[0.3889], W =[0.3123 0.9770], b =[-4.2276],               \n","pred =[0.3381 0.4882 0.2642 0.7828 0.6404 0.7759],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [7100], Train_cost =[0.3865], W =[0.3168 0.9860], b =[-4.2757],               \n","pred =[0.3353 0.4873 0.2618 0.7838 0.6417 0.7777],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [7200], Train_cost =[0.3841], W =[0.3212 0.9949], b =[-4.3235],               \n","pred =[0.3326 0.4865 0.2594 0.7847 0.6430 0.7794],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [7300], Train_cost =[0.3817], W =[0.3256 1.0038], b =[-4.3710],               \n","pred =[0.3300 0.4857 0.2571 0.7857 0.6443 0.7811],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [7400], Train_cost =[0.3794], W =[0.3299 1.0126], b =[-4.4181],               \n","pred =[0.3273 0.4849 0.2548 0.7867 0.6455 0.7828],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [7500], Train_cost =[0.3771], W =[0.3343 1.0214], b =[-4.4650],               \n","pred =[0.3247 0.4841 0.2525 0.7876 0.6468 0.7845],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [7600], Train_cost =[0.3749], W =[0.3386 1.0301], b =[-4.5115],               \n","pred =[0.3221 0.4833 0.2503 0.7885 0.6480 0.7861],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [7700], Train_cost =[0.3726], W =[0.3429 1.0387], b =[-4.5578],               \n","pred =[0.3196 0.4825 0.2481 0.7895 0.6492 0.7878],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [7800], Train_cost =[0.3704], W =[0.3471 1.0473], b =[-4.6037],               \n","pred =[0.3170 0.4817 0.2459 0.7904 0.6504 0.7894],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [7900], Train_cost =[0.3683], W =[0.3513 1.0559], b =[-4.6494],               \n","pred =[0.3145 0.4809 0.2437 0.7913 0.6516 0.7910],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [8000], Train_cost =[0.3661], W =[0.3555 1.0644], b =[-4.6947],               \n","pred =[0.3120 0.4801 0.2416 0.7922 0.6528 0.7925],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [8100], Train_cost =[0.3640], W =[0.3597 1.0728], b =[-4.7398],               \n","pred =[0.3096 0.4793 0.2395 0.7931 0.6540 0.7941],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [8200], Train_cost =[0.3619], W =[0.3638 1.0812], b =[-4.7846],               \n","pred =[0.3072 0.4786 0.2374 0.7940 0.6552 0.7956],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [8300], Train_cost =[0.3598], W =[0.3679 1.0895], b =[-4.8291],               \n","pred =[0.3048 0.4778 0.2353 0.7948 0.6563 0.7971],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [8400], Train_cost =[0.3578], W =[0.3720 1.0978], b =[-4.8733],               \n","pred =[0.3024 0.4770 0.2333 0.7957 0.6575 0.7986],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [8500], Train_cost =[0.3558], W =[0.3760 1.1060], b =[-4.9173],               \n","pred =[0.3000 0.4763 0.2313 0.7966 0.6586 0.8001],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [8600], Train_cost =[0.3538], W =[0.3801 1.1142], b =[-4.9610],               \n","pred =[0.2977 0.4755 0.2293 0.7974 0.6597 0.8016],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [8700], Train_cost =[0.3518], W =[0.3841 1.1224], b =[-5.0044],               \n","pred =[0.2954 0.4748 0.2273 0.7983 0.6609 0.8030],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [8800], Train_cost =[0.3499], W =[0.3880 1.1305], b =[-5.0475],               \n","pred =[0.2932 0.4740 0.2254 0.7991 0.6620 0.8045],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [8900], Train_cost =[0.3479], W =[0.3920 1.1385], b =[-5.0904],               \n","pred =[0.2909 0.4733 0.2235 0.8000 0.6631 0.8059],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [9000], Train_cost =[0.3461], W =[0.3959 1.1465], b =[-5.1331],               \n","pred =[0.2887 0.4725 0.2216 0.8008 0.6641 0.8073],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [9100], Train_cost =[0.3442], W =[0.3998 1.1544], b =[-5.1754],               \n","pred =[0.2865 0.4718 0.2197 0.8016 0.6652 0.8087],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [9200], Train_cost =[0.3423], W =[0.4037 1.1623], b =[-5.2175],               \n","pred =[0.2843 0.4711 0.2179 0.8024 0.6663 0.8100],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [9300], Train_cost =[0.3405], W =[0.4075 1.1702], b =[-5.2594],               \n","pred =[0.2821 0.4703 0.2160 0.8032 0.6673 0.8114],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [9400], Train_cost =[0.3387], W =[0.4113 1.1780], b =[-5.3010],               \n","pred =[0.2800 0.4696 0.2142 0.8040 0.6684 0.8127],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [9500], Train_cost =[0.3369], W =[0.4151 1.1857], b =[-5.3424],               \n","pred =[0.2779 0.4689 0.2124 0.8048 0.6694 0.8140],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [9600], Train_cost =[0.3351], W =[0.4189 1.1935], b =[-5.3835],               \n","pred =[0.2758 0.4682 0.2107 0.8056 0.6705 0.8153],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [9700], Train_cost =[0.3334], W =[0.4227 1.2011], b =[-5.4244],               \n","pred =[0.2737 0.4675 0.2089 0.8064 0.6715 0.8166],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [9800], Train_cost =[0.3317], W =[0.4264 1.2088], b =[-5.4650],               \n","pred =[0.2717 0.4667 0.2072 0.8071 0.6725 0.8179],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [9900], Train_cost =[0.3300], W =[0.4301 1.2163], b =[-5.5054],               \n","pred =[0.2697 0.4660 0.2055 0.8079 0.6735 0.8191],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","\n","Run_count : [10000], Train_cost =[0.3283], W =[0.4338 1.2239], b =[-5.5456],               \n","pred =[0.2677 0.4653 0.2038 0.8087 0.6745 0.8204],               \n","pred_Y = [0 0 0 1 1 1 ],               \n","true_Y=  [0 0 0 1 1 1 ],               \n","accuracy = [100.00%] \n","Optimization Finished!\n"]}]}]}